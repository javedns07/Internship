{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac95c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a2c52",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1529b0a",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "        \n",
    "A)Rank \n",
    "\n",
    "B) Name \n",
    "\n",
    "C) Artist \n",
    "\n",
    "D) Upload date \n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357a6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load Amazon website\n",
    "driver.get(\" https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "# Locating page for top videos by xpath\n",
    "\n",
    "search2= driver.find_element(By.XPATH,'//li[@class=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\"][1]/a/div')\n",
    "search2.click()\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "# Empty lists\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views_billions=[]\n",
    "\n",
    "# scraping information about most viewed videos on YouTube from Wikipedia\n",
    "\n",
    "#scraping the Rank\n",
    "Rank= [str(i) for i in range(1, 31)]\n",
    "\n",
    "\n",
    "#scraping the Video Name \n",
    "name=driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div/table[2]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for w in name:\n",
    "        Name.append(w.text)\n",
    "except:\n",
    "    Name.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Artist\n",
    "art=driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div/table[2]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for a in art:\n",
    "        Artist.append(a.text)\n",
    "except:\n",
    "    Artist.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Upload_Date \n",
    "date=driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div/table[2]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for d in date:\n",
    "        Upload_Date.append(d.text)\n",
    "except:\n",
    "    Upload_Date.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Views \n",
    "viw=driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div/table[2]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for v in viw:\n",
    "        Views_billions.append(v.text)\n",
    "except:\n",
    "    Views_billions.append('-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3742603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Name':Name,'Artist':Artist,'Upload_Date':Upload_Date,'Views_billions':Views_billions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f18926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views_billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Roar\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[48]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Dark Horse\"[49]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0     1                            \"Baby Shark Dance\"[6]   \n",
       "1     2                                   \"Despacito\"[9]   \n",
       "2     3                       \"Johny Johny Yes Papa\"[17]   \n",
       "3     4                                  \"Bath Song\"[18]   \n",
       "4     5                               \"Shape of You\"[19]   \n",
       "5     6                              \"See You Again\"[22]   \n",
       "6     7                          \"Wheels on the Bus\"[27]   \n",
       "7     8                \"Phonics Song with Two Words\"[28]   \n",
       "8     9                                \"Uptown Funk\"[29]   \n",
       "9    10  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10   11                              \"Gangnam Style\"[31]   \n",
       "11   12   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12   13                             \"Dame Tu Cosita\"[37]   \n",
       "13   14                                     \"Axel F\"[38]   \n",
       "14   15                                      \"Sugar\"[39]   \n",
       "15   16                             \"Counting Stars\"[40]   \n",
       "16   17                        \"Baa Baa Black Sheep\"[41]   \n",
       "17   18                                       \"Roar\"[42]   \n",
       "18   19                             \"Lakdi Ki Kathi\"[43]   \n",
       "19   20           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "20   21                                      \"Sorry\"[45]   \n",
       "21   22                          \"Thinking Out Loud\"[46]   \n",
       "22   23          \"Humpty the train on a fruits ride\"[47]   \n",
       "23   24                      \"Shree Hanuman Chalisa\"[48]   \n",
       "24   25                                 \"Dark Horse\"[49]   \n",
       "25   26                                    \"Perfect\"[50]   \n",
       "26   27                                 \"Let Her Go\"[51]   \n",
       "27   28                                      \"Faded\"[52]   \n",
       "28   29                             \"Girls Like You\"[53]   \n",
       "29   30                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload_Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                                Psy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "17                                         Katy Perry  September 5, 2013   \n",
       "18                                       Jingle Toons      June 14, 2018   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "24                                         Katy Perry  February 20, 2014   \n",
       "25                                         Ed Sheeran   November 9, 2017   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "   Views_billions  \n",
       "0           14.09  \n",
       "1            8.38  \n",
       "2            6.87  \n",
       "3            6.62  \n",
       "4            6.20  \n",
       "5            6.17  \n",
       "6            5.88  \n",
       "7            5.70  \n",
       "8            5.15  \n",
       "9            5.07  \n",
       "10           5.05  \n",
       "11           4.58  \n",
       "12           4.55  \n",
       "13           4.34  \n",
       "14           4.00  \n",
       "15           3.97  \n",
       "16           3.96  \n",
       "17           3.96  \n",
       "18           3.91  \n",
       "19           3.85  \n",
       "20           3.77  \n",
       "21           3.73  \n",
       "22           3.73  \n",
       "23           3.69  \n",
       "24           3.67  \n",
       "25           3.67  \n",
       "26           3.61  \n",
       "27           3.59  \n",
       "28           3.56  \n",
       "29           3.55  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce22012",
   "metadata": {},
   "source": [
    "# Question-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3ab35",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/. \n",
    "You need to find following details: \n",
    "    \n",
    "A) Series \n",
    "\n",
    "B) Place \n",
    "\n",
    "C) Date \n",
    "\n",
    "D) Time \n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8f362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27f5d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load google maps\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "# Locatingthe international fixture page through code.\n",
    "search1_click=driver.find_element(By.XPATH,'//*[@class=\"w-100 tab-pane fade  show active \"]/ul/div[1]/a[2]')\n",
    "search1_click.click()\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "# Empty Lists\n",
    "Team_Name=[]\n",
    "Series_Name=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "# scraping information about team India’s international fixtures from bcci.tv. \n",
    "\n",
    "#scraping the Team_Name \n",
    "Team=driver.find_elements(By.XPATH,'//div[@class=\"col-lg-3 col-md-3 col-sm-12\"]/div/div/h5')\n",
    "try:\n",
    "    for w in Team:\n",
    "        Team_Name.append(w.text)\n",
    "except:\n",
    "    Team_Name.append('-')\n",
    "    \n",
    "\n",
    "#scraping the Series_Name\n",
    "Series=driver.find_elements(By.XPATH,'//div[@class=\"match-info\"]/div/span[1]')\n",
    "try:\n",
    "    for a in Series:\n",
    "        Series_Name.append(a.text)\n",
    "except:\n",
    "    Series_Name.append('-')\n",
    "    \n",
    "       \n",
    "#scraping the Place \n",
    "Pal=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "try:\n",
    "    for d in Pal:\n",
    "        Place.append(d.text)\n",
    "except:\n",
    "    Place.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "#scraping the Date \n",
    "Dat=driver.find_elements(By.XPATH,'//div[@class=\"col-lg-3 col-md-3 col-sm-12\"]/div/div/div[2]/div[1]')\n",
    "try:\n",
    "    for v in Dat:\n",
    "        Date.append(v.text)\n",
    "except:\n",
    "    Date.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Time \n",
    "Tim=driver.find_elements(By.XPATH,'//div[@class=\"col-lg-3 col-md-3 col-sm-12\"]/div/div/div[2]/div[2]')\n",
    "try:\n",
    "    for v in Tim:\n",
    "        Time.append(v.text)\n",
    "except:\n",
    "    Time.append('-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8475cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Series_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a81631f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Team_Name':Team_Name,'Series_Name':Series_Name,'Place':Place,'Date':Date,'Time':Time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "733412a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Series_Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>5th T20I</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Team_Name Series_Name  \\\n",
       "0  ENGLAND TOUR OF INDIA 2023-24    5th Test   \n",
       "1    INDIA TOUR OF ZIMBABWE 2024    1st T20I   \n",
       "2    INDIA TOUR OF ZIMBABWE 2024    2nd T20I   \n",
       "3    INDIA TOUR OF ZIMBABWE 2024    3rd T20I   \n",
       "4    INDIA TOUR OF ZIMBABWE 2024    4th T20I   \n",
       "5    INDIA TOUR OF ZIMBABWE 2024    5th T20I   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0  Himachal Pradesh Cricket Association Stadium, ...  7 MARCH, 2024   \n",
       "1                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "2                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "3                         Harare Sports Club, Harare  10 JULY, 2024   \n",
       "4                         Harare Sports Club, Harare  13 JULY, 2024   \n",
       "5                         Harare Sports Club, Harare  14 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  9:30 AM IST  \n",
       "1  8:00 PM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622308d5",
   "metadata": {},
   "source": [
    "# Question-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233f10f",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details:\n",
    "    \n",
    "A) Rank \n",
    "\n",
    "B) State \n",
    "\n",
    "C) GSDP(18-19)- at current prices \n",
    "\n",
    "D) GSDP(19-20)- at current prices \n",
    "\n",
    "E) Share(18-19) \n",
    "\n",
    "F) GDP($ billion) \n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee288284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load google maps\n",
    "driver.get(\" http://statisticstimes.com/\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "sleep(3)\n",
    "\n",
    "economy = driver.find_element(By.XPATH,'//*[@class=\"dropdown\"][2]/button')     \n",
    "economy.click()\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "ind = driver.find_element(By.XPATH,'//*[@class=\"navbar\"]/div[2]/div/a[3]')\n",
    "ind.click()\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "\n",
    "gdp = driver.find_element(By.XPATH,'//*[@style=\"list-style-type:none;margin-left:20px;\"]/li[1]/a')    \n",
    "gdp.click()\n",
    "\n",
    "\n",
    "# Empty Lists\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_Current=[]\n",
    "GSDP_Previous=[]\n",
    "Share=[]\n",
    "GDP=[]\n",
    "\n",
    "\n",
    "# scraping information about State-wise GDP of India\n",
    "#scraping the Rank \n",
    "Rak=driver.find_elements(By.XPATH,'//*[@id=\"table_id_wrapper\"]/table/tbody/tr/td[1]')\n",
    "try:\n",
    "    for w in Rak:\n",
    "        Rank.append(w.text)\n",
    "except:\n",
    "    Rank.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the State\n",
    "Stat=driver.find_elements(By.XPATH,'//*[@id=\"table_id_wrapper\"]/table/tbody/tr/td[2]')\n",
    "try:\n",
    "    for a in Stat:\n",
    "        State.append(a.text)\n",
    "except:\n",
    "    State.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the GSDP_Current \n",
    "Current=driver.find_elements(By.XPATH,'//*[@id=\"table_id_wrapper\"]/table/tbody/tr/td[3]')\n",
    "try:\n",
    "    for d in Current:\n",
    "        GSDP_Current.append(d.text)\n",
    "except:\n",
    "    GSDP_Current.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the GSDP_Previous \n",
    "Previous=driver.find_elements(By.XPATH,'//*[@id=\"table_id_wrapper\"]/table/tbody/tr/td[4]')\n",
    "try:\n",
    "    for v in Previous:\n",
    "        GSDP_Previous.append(v.text)\n",
    "except:\n",
    "    GSDP_Previous.append('-')\n",
    "    \n",
    "#scraping the Share\n",
    "Shar=driver.find_elements(By.XPATH,'//*[@id=\"table_id_wrapper\"]/table/tbody/tr/td[5]')\n",
    "try:\n",
    "    for a in Shar:\n",
    "        Share.append(a.text)\n",
    "except:\n",
    "    Share.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the GDP \n",
    "GDP_=driver.find_elements(By.XPATH,'//*[@id=\"table_id_wrapper\"]/table/tbody/tr/td[6]')\n",
    "try:\n",
    "    for d in GDP_:\n",
    "        GDP.append(d.text)\n",
    "except:\n",
    "    GDP.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7d451e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c9bf586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'State':State,'Share In GDP':Share,'GSDP_Current':GSDP_Current,'GSDP_Previous':GSDP_Previous,'GDP of State':GDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2831cf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share In GDP</th>\n",
       "      <th>GSDP_Current</th>\n",
       "      <th>GSDP_Previous</th>\n",
       "      <th>GDP of State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>-</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>1,363,926</td>\n",
       "      <td>183.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>163.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>1,136,137</td>\n",
       "      <td>152.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>152.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>4.81%</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>1,128,907</td>\n",
       "      <td>151.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>-</td>\n",
       "      <td>932,470</td>\n",
       "      <td>125.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>904,642</td>\n",
       "      <td>121.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>994,154</td>\n",
       "      <td>870,665</td>\n",
       "      <td>116.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2.86%</td>\n",
       "      <td>774,869</td>\n",
       "      <td>670,881</td>\n",
       "      <td>90.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>87.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>673,107</td>\n",
       "      <td>614,227</td>\n",
       "      <td>82.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>493,167</td>\n",
       "      <td>412,612</td>\n",
       "      <td>55.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>457,608</td>\n",
       "      <td>406,416</td>\n",
       "      <td>54.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>48.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>302,621</td>\n",
       "      <td>272,159</td>\n",
       "      <td>36.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>227,927</td>\n",
       "      <td>199,917</td>\n",
       "      <td>26.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>195,405</td>\n",
       "      <td>176,269</td>\n",
       "      <td>23.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>-</td>\n",
       "      <td>82,604</td>\n",
       "      <td>11.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>8.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>-</td>\n",
       "      <td>45,635</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>-</td>\n",
       "      <td>44,238</td>\n",
       "      <td>5.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>5.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>5.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>4.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "      <td>35,124</td>\n",
       "      <td>4.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>-</td>\n",
       "      <td>31,913</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>3.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Share In GDP GSDP_Current GSDP_Previous  \\\n",
       "0     1                Maharashtra       13.24%            -     3,108,022   \n",
       "1     2                 Tamil Nadu        8.82%    2,364,514     2,071,286   \n",
       "2     3              Uttar Pradesh        8.41%    2,257,575     1,974,532   \n",
       "3     4                  Karnataka        8.36%    2,241,368     1,962,725   \n",
       "4     5                    Gujarat        8.25%            -     1,937,066   \n",
       "5     6                West Bengal        5.81%    1,554,992     1,363,926   \n",
       "6     7                  Rajasthan        5.19%    1,413,620     1,218,193   \n",
       "7     8             Madhya Pradesh        4.84%    1,322,821     1,136,137   \n",
       "8     9             Andhra Pradesh        4.83%    1,317,728     1,133,837   \n",
       "9    10                  Telangana        4.81%    1,313,391     1,128,907   \n",
       "10   11                     Kerala        3.97%            -       932,470   \n",
       "11   12                      Delhi        3.85%    1,043,759       904,642   \n",
       "12   13                    Haryana        3.71%      994,154       870,665   \n",
       "13   14                     Odisha        2.86%      774,869       670,881   \n",
       "14   15                      Bihar        2.77%      751,396       650,302   \n",
       "15   16                     Punjab        2.62%      673,107       614,227   \n",
       "16   17                      Assam        1.76%      493,167       412,612   \n",
       "17   18               Chhattisgarh        1.73%      457,608       406,416   \n",
       "18   19                  Jharkhand        1.53%      393,722       358,863   \n",
       "19   20                Uttarakhand        1.16%      302,621       272,159   \n",
       "20   21         Jammu & Kashmir-UT        0.85%      227,927       199,917   \n",
       "21   22           Himachal Pradesh        0.75%      195,405       176,269   \n",
       "22   23                        Goa        0.35%            -        82,604   \n",
       "23   24                    Tripura        0.27%       72,636        62,550   \n",
       "24   25                 Chandigarh        0.19%            -        45,635   \n",
       "25   26                 Puducherry        0.19%            -        44,238   \n",
       "26   27                  Meghalaya        0.17%       42,697        38,785   \n",
       "27   28                     Sikkim        0.16%       42,756        37,557   \n",
       "28   29                    Manipur        0.16%            -        36,594   \n",
       "29   30          Arunachal Pradesh        0.15%            -        35,124   \n",
       "30   31                   Nagaland        0.14%            -        31,913   \n",
       "31   32                    Mizoram        0.12%            -        27,824   \n",
       "32   33  Andaman & Nicobar Islands        0.04%            -        10,371   \n",
       "\n",
       "   GDP of State  \n",
       "0       417.163  \n",
       "1       278.011  \n",
       "2       265.024  \n",
       "3       263.440  \n",
       "4       259.996  \n",
       "5       183.068  \n",
       "6       163.507  \n",
       "7       152.494  \n",
       "8       152.185  \n",
       "9       151.523  \n",
       "10      125.157  \n",
       "11      121.422  \n",
       "12      116.862  \n",
       "13       90.047  \n",
       "14       87.284  \n",
       "15       82.442  \n",
       "16       55.381  \n",
       "17       54.550  \n",
       "18       48.167  \n",
       "19       36.530  \n",
       "20       26.833  \n",
       "21       23.659  \n",
       "22       11.087  \n",
       "23        8.396  \n",
       "24        6.125  \n",
       "25        5.938  \n",
       "26        5.206  \n",
       "27        5.041  \n",
       "28        4.912  \n",
       "29        4.714  \n",
       "30        4.283  \n",
       "31        3.735  \n",
       "32        1.392  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725cac2",
   "metadata": {},
   "source": [
    "# Question-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa926c4",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af97653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load google maps\n",
    "driver.get(\"https://github.com/\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "Menu_1 = driver.find_element(By.XPATH,'//*[@class=\"d-lg-flex list-style-none\"]/li[3]/button')     \n",
    "Menu_1.click()\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "trending = driver.find_element(By.XPATH,'//*[@class=\"d-lg-flex list-style-none\"]/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()\n",
    "\n",
    "sleep(4)\n",
    "\n",
    "# Empty Lists\n",
    "Title=[]\n",
    "Description=[]\n",
    "Contributors_count=[]\n",
    "Language=[]\n",
    "\n",
    "# scraping information about trending repositories on Github\n",
    "\n",
    "#scraping the Title \n",
    "Tit=driver.find_elements(By.XPATH,'//*[@class=\"Box-row\"]/h2/a')\n",
    "try:\n",
    "    for w in Tit[0:22]:\n",
    "        Title.append(w.text)\n",
    "except:\n",
    "    Title.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Description\n",
    "Descr=driver.find_elements(By.XPATH,'//*[@class=\"Box-row\"]/p')\n",
    "try:\n",
    "    for a in Descr[0:22]:\n",
    "        Description.append(a.text)\n",
    "except:\n",
    "    Description.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Contributors_count \n",
    "count=driver.find_elements(By.XPATH,'//*[@class=\"Box-row\"]/div[2]/a[2]')\n",
    "try:\n",
    "    for d in count[0:22]:\n",
    "        Contributors_count.append(d.text)\n",
    "except:\n",
    "    Contributors_count.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Language \n",
    "Lang=driver.find_elements(By.XPATH,'//*[@class=\"Box-row\"]/div[2]/span[1]')\n",
    "try:\n",
    "    for v in Lang[0:22]:\n",
    "        Language.append(v.text)\n",
    "except:\n",
    "    Language.append('-')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be54e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Title':Title,'Description':Description,'Contributors_count':Contributors_count,'Language':Language})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50324fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WongKinYiu / yolov9</td>\n",
       "      <td>Implementation of paper - YOLOv9: Learning Wha...</td>\n",
       "      <td>510</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>massgravel / Microsoft-Activation-Scripts</td>\n",
       "      <td>A Windows and Office activator using HWID / Oh...</td>\n",
       "      <td>6,472</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollama / ollama</td>\n",
       "      <td>Get up and running with Llama 2, Mistral, Gemm...</td>\n",
       "      <td>2,662</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vvbbnn00 / WARP-Clash-API</td>\n",
       "      <td>该项目可以让你通过订阅的方式使用Cloudflare WARP+，自动获取流量。This p...</td>\n",
       "      <td>472</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qarmin / czkawka</td>\n",
       "      <td>Multi functional app to find duplicates, empty...</td>\n",
       "      <td>520</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mttaggart / I-S00N</td>\n",
       "      <td>Anxun Shanghai (I-SOON) Data Dump Translations...</td>\n",
       "      <td>278</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MHSanaei / 3x-ui</td>\n",
       "      <td>Xray panel supporting multi-protocol multi-use...</td>\n",
       "      <td>1,181</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jellyfin / jellyfin</td>\n",
       "      <td>The Free Software Media System</td>\n",
       "      <td>2,648</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google / gemma.cpp</td>\n",
       "      <td>lightweight, standalone C++ inference engine f...</td>\n",
       "      <td>349</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>59,135</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>public-apis / public-apis</td>\n",
       "      <td>A collective list of free APIs</td>\n",
       "      <td>30,720</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gunnarmorling / 1brc</td>\n",
       "      <td>1️⃣🐝🏎️ The One Billion Row Challenge -- A fun ...</td>\n",
       "      <td>1,270</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KillianLucas / open-interpreter</td>\n",
       "      <td>A natural language interface for computers</td>\n",
       "      <td>3,561</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ossu / computer-science</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>19,860</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mouredev / Hello-Python</td>\n",
       "      <td>Curso para aprender el lenguaje de programació...</td>\n",
       "      <td>1,354</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ashishps1 / awesome-system-design-resources</td>\n",
       "      <td>This repository contains System Design resourc...</td>\n",
       "      <td>1,950</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>state-spaces / mamba</td>\n",
       "      <td>Joplin - the secure note taking and to-do app ...</td>\n",
       "      <td>547</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>laurent22 / joplin</td>\n",
       "      <td>Performance-portable, length-agnostic SIMD wit...</td>\n",
       "      <td>4,376</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OpenCodeInterpreter / OpenCodeInterpreter</td>\n",
       "      <td>The Python Risk Identification Tool for genera...</td>\n",
       "      <td>75</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>zksync / credo</td>\n",
       "      <td>shadcn/ui, but for Svelte. ✨</td>\n",
       "      <td>948</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>google / highway</td>\n",
       "      <td>Dev tool that writes scalable apps from scratc...</td>\n",
       "      <td>276</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azure / PyRIT</td>\n",
       "      <td>A multi-platform library for OpenGL, OpenGL ES...</td>\n",
       "      <td>96</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                           WongKinYiu / yolov9   \n",
       "1     massgravel / Microsoft-Activation-Scripts   \n",
       "2                               ollama / ollama   \n",
       "3                     vvbbnn00 / WARP-Clash-API   \n",
       "4                              qarmin / czkawka   \n",
       "5                            mttaggart / I-S00N   \n",
       "6                              MHSanaei / 3x-ui   \n",
       "7                           jellyfin / jellyfin   \n",
       "8                            google / gemma.cpp   \n",
       "9      EbookFoundation / free-programming-books   \n",
       "10                    public-apis / public-apis   \n",
       "11                         gunnarmorling / 1brc   \n",
       "12              KillianLucas / open-interpreter   \n",
       "13                      ossu / computer-science   \n",
       "14                      mouredev / Hello-Python   \n",
       "15  ashishps1 / awesome-system-design-resources   \n",
       "16                         state-spaces / mamba   \n",
       "17                           laurent22 / joplin   \n",
       "18    OpenCodeInterpreter / OpenCodeInterpreter   \n",
       "19                               zksync / credo   \n",
       "20                             google / highway   \n",
       "21                                Azure / PyRIT   \n",
       "\n",
       "                                          Description Contributors_count  \\\n",
       "0   Implementation of paper - YOLOv9: Learning Wha...                510   \n",
       "1   A Windows and Office activator using HWID / Oh...              6,472   \n",
       "2   Get up and running with Llama 2, Mistral, Gemm...              2,662   \n",
       "3   该项目可以让你通过订阅的方式使用Cloudflare WARP+，自动获取流量。This p...                472   \n",
       "4   Multi functional app to find duplicates, empty...                520   \n",
       "5   Anxun Shanghai (I-SOON) Data Dump Translations...                278   \n",
       "6   Xray panel supporting multi-protocol multi-use...              1,181   \n",
       "7                      The Free Software Media System              2,648   \n",
       "8   lightweight, standalone C++ inference engine f...                349   \n",
       "9                📚 Freely available programming books             59,135   \n",
       "10                     A collective list of free APIs             30,720   \n",
       "11  1️⃣🐝🏎️ The One Billion Row Challenge -- A fun ...              1,270   \n",
       "12         A natural language interface for computers              3,561   \n",
       "13  🎓 Path to a free self-taught education in Comp...             19,860   \n",
       "14  Curso para aprender el lenguaje de programació...              1,354   \n",
       "15  This repository contains System Design resourc...              1,950   \n",
       "16  Joplin - the secure note taking and to-do app ...                547   \n",
       "17  Performance-portable, length-agnostic SIMD wit...              4,376   \n",
       "18  The Python Risk Identification Tool for genera...                 75   \n",
       "19                       shadcn/ui, but for Svelte. ✨                948   \n",
       "20  Dev tool that writes scalable apps from scratc...                276   \n",
       "21  A multi-platform library for OpenGL, OpenGL ES...                 96   \n",
       "\n",
       "      Language  \n",
       "0       Python  \n",
       "1    Batchfile  \n",
       "2           Go  \n",
       "3       Python  \n",
       "4         Rust  \n",
       "5     Built by  \n",
       "6   JavaScript  \n",
       "7           C#  \n",
       "8          C++  \n",
       "9     Built by  \n",
       "10      Python  \n",
       "11        Java  \n",
       "12      Python  \n",
       "13    Built by  \n",
       "14      Python  \n",
       "15    Built by  \n",
       "16      Python  \n",
       "17  TypeScript  \n",
       "18      Python  \n",
       "19    Built by  \n",
       "20         C++  \n",
       "21      Python  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ce8042",
   "metadata": {},
   "source": [
    "# Question-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8098e7",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "\n",
    "following details: \n",
    "\n",
    "A) Song name m\n",
    "\n",
    "B) Artist name \n",
    "\n",
    "C) Last week rank \n",
    "\n",
    "D) Peak rank \n",
    "\n",
    "E) Weeks on board \n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59ab01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load google maps\n",
    "driver.get(\"https:/www.billboard.com/\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c0f4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Menu_1 = driver.find_element(By.XPATH,'//*[@class=\"u-overflow-hidden \"]/header/div/div[4]/div/div/div/button')     \n",
    "Menu_1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45a4f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = driver.find_element(By.XPATH,'//*[@class=\"mega-menu__main // js-MegaMenu lrv-u-margin-lr-auto lrv-u-width-100p u-max-width-1000 u-flex-1\"]/ul/li[1]/ul/li[2]/a')\n",
    "top_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "287cba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Lists\n",
    "Song_name=[]\n",
    "Artist_name=[] \n",
    "Last_week_rank=[] \n",
    "Peak_rank =[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6791a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Song_name \n",
    "Song=driver.find_elements(By.XPATH,'//*[@class=\"u-max-width-970 lrv-u-margin-lr-auto\"]/div[2]/div/ul/li[4]/ul/li/h3')\n",
    "try:\n",
    "    for w in Song:\n",
    "        Song_name.append(w.text)\n",
    "except:\n",
    "    Song_name.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Artist_name\n",
    "Art=driver.find_elements(By.XPATH,'//*[@class=\"u-max-width-970 lrv-u-margin-lr-auto\"]/div[2]/div/ul/li[4]/ul/li[1]/span')\n",
    "try:\n",
    "    for a in Art:\n",
    "        Artist_name.append(a.text)\n",
    "except:\n",
    "    Artist_name.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Last_week_rank \n",
    "Last=driver.find_elements(By.XPATH,'//*[@class=\"u-max-width-970 lrv-u-margin-lr-auto\"]/div[2]/div/ul/li[4]/ul/li[4]/span')\n",
    "try:\n",
    "    for d in Last:\n",
    "        Last_week_rank.append(d.text)\n",
    "except:\n",
    "    Last_week_rank.append('-')\n",
    "\n",
    "     \n",
    "#scraping the Peak_rank \n",
    "Peak=driver.find_elements(By.XPATH,'//*[@class=\"u-max-width-970 lrv-u-margin-lr-auto\"]/div[2]/div/ul/li[4]/ul/li[5]/span')\n",
    "try:\n",
    "    for v in Peak:\n",
    "        Peak_rank.append(v.text)\n",
    "except:\n",
    "    Peak_rank.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Weeks_on_board \n",
    "Weeks=driver.find_elements(By.XPATH,'//*[@class=\"u-max-width-970 lrv-u-margin-lr-auto\"]/div[2]/div/ul/li[4]/ul/li[6]/span')\n",
    "try:\n",
    "    for f in Weeks:\n",
    "        Weeks_on_board.append(f.text)\n",
    "except:\n",
    "    Weeks_on_board.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04290df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Song_name':Song_name,'Artist_name':Artist_name,'Last_week_rank':Last_week_rank,'Peak_rank':Peak_rank,'Weeks_on_board':Weeks_on_board})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03a93195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas Hold 'Em</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carnival</td>\n",
       "      <td>¥$: Kanye West &amp; Ty Dolla $ign Featuring Rich ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Talking</td>\n",
       "      <td>¥$: Kanye West &amp; Ty Dolla $ign Featuring North...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Where It Ends</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td>-</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wondering Why</td>\n",
       "      <td>The Red Clay Strays</td>\n",
       "      <td>-</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Northern Attitude</td>\n",
       "      <td>Noah Kahan With Hozier</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Song_name                                        Artist_name  \\\n",
       "0      Texas Hold 'Em                                            Beyonce   \n",
       "1         Lovin On Me                                        Jack Harlow   \n",
       "2        Lose Control                                        Teddy Swims   \n",
       "3            Carnival  ¥$: Kanye West & Ty Dolla $ign Featuring Rich ...   \n",
       "4    Beautiful Things                                       Benson Boone   \n",
       "..                ...                                                ...   \n",
       "95            Talking  ¥$: Kanye West & Ty Dolla $ign Featuring North...   \n",
       "96             Monaco                                          Bad Bunny   \n",
       "97      Where It Ends                                   Bailey Zimmerman   \n",
       "98      Wondering Why                                The Red Clay Strays   \n",
       "99  Northern Attitude                             Noah Kahan With Hozier   \n",
       "\n",
       "   Last_week_rank Peak_rank Weeks_on_board  \n",
       "0               2         1              2  \n",
       "1               1         1             15  \n",
       "2               5         2             28  \n",
       "3               3         3              2  \n",
       "4               4         3              5  \n",
       "..            ...       ...            ...  \n",
       "95             30        30              2  \n",
       "96             97         5             19  \n",
       "97              -        32              8  \n",
       "98              -        71              8  \n",
       "99             75        37             12  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6430e",
   "metadata": {},
   "source": [
    "# Question-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc15838",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels. \n",
    "\n",
    "A) Book name \n",
    "\n",
    "B) Author name \n",
    "\n",
    "C) Volumes sold \n",
    "\n",
    "D) Publisher \n",
    "\n",
    "E) Genre \n",
    "\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe164d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load google maps\n",
    "driver.get(\" https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "# Empty Lists\n",
    "Rank=[]\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#scraping the Rank \n",
    "Ran=driver.find_elements(By.XPATH,'//*[@class=\"embed block\"]/table/tbody/tr/td[1]')\n",
    "try:\n",
    "    for r in Ran:\n",
    "        Rank.append(r.text)\n",
    "except:\n",
    "    Rank.append('-')\n",
    "\n",
    "\n",
    "#scraping the Book_name \n",
    "name=driver.find_elements(By.XPATH,'//*[@class=\"embed block\"]/table/tbody/tr/td[2]')\n",
    "try:\n",
    "    for w in name:\n",
    "        Book_name.append(w.text)\n",
    "except:\n",
    "    Book_name.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Author_name\n",
    "Author=driver.find_elements(By.XPATH,'//*[@class=\"embed block\"]/table/tbody/tr/td[3]')\n",
    "try:\n",
    "    for a in Author:\n",
    "        Author_name.append(a.text)\n",
    "except:\n",
    "    Author_name.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Volumes_sold \n",
    "sold=driver.find_elements(By.XPATH,'//*[@class=\"embed block\"]/table/tbody/tr/td[4]')\n",
    "try:\n",
    "    for d in sold:\n",
    "        Volumes_sold.append(d.text)\n",
    "except:\n",
    "    Volumes_sold.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Publisher \n",
    "Pub=driver.find_elements(By.XPATH,'//*[@class=\"embed block\"]/table/tbody/tr/td[5]')\n",
    "try:\n",
    "    for v in Pub:\n",
    "        Publisher.append(v.text)\n",
    "except:\n",
    "    Publisher.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Genre \n",
    "Gen=driver.find_elements(By.XPATH,'//*[@class=\"embed block\"]/table/tbody/tr/td[6]')\n",
    "try:\n",
    "    for f in Gen:\n",
    "        Genre.append(f.text)\n",
    "except:\n",
    "    Genre.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0b78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Book_name':Book_name,'Author_name':Author_name,'Volumes_sold':Volumes_sold,'Publisher':Publisher,'Genre':Genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f96e7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                          Book_name       Author_name  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aebc48",
   "metadata": {},
   "source": [
    "# Question-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94c68d",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "\n",
    "to find the following details: \n",
    "\n",
    "A) Name \n",
    "\n",
    "B) Year span \n",
    "\n",
    "C) Genre \n",
    "\n",
    "D) Run time \n",
    "\n",
    "E) Ratings \n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6bce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load google maps\n",
    "driver.get(\"https://www.imdb.com/list/ls512407256/\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "# Empty Lists\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genres=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "#scraping the Rank \n",
    "Ran=driver.find_elements(By.XPATH,'//*[@class=\"lister list detail sub-list\"]/div[3]/div/div/h3/span[1]')\n",
    "try:\n",
    "    for r in Ran:\n",
    "        Rank.append(r.text)\n",
    "except:\n",
    "    Rank.append('-')\n",
    "\n",
    "\n",
    "#scraping the Name \n",
    "name=driver.find_elements(By.XPATH,'//*[@class=\"lister list detail sub-list\"]/div[3]/div/div/h3/a')\n",
    "try:\n",
    "    for w in name:\n",
    "        Name.append(w.text)\n",
    "except:\n",
    "    Name.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Year_span\n",
    "span=driver.find_elements(By.XPATH,'//*[@class=\"lister list detail sub-list\"]/div[3]/div/div/h3/span[2]')\n",
    "try:\n",
    "    for a in span:\n",
    "        Year_span.append(a.text)\n",
    "except:\n",
    "    Year_span.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Genres \n",
    "Gen=driver.find_elements(By.XPATH,'//*[@class=\"lister list detail sub-list\"]/div[3]/div/div/p/span[5]')\n",
    "try:\n",
    "    for d in Gen:\n",
    "        Genres.append(d.text)\n",
    "except:\n",
    "    Genres.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Run_time \n",
    "time=driver.find_elements(By.XPATH,'//*[@class=\"lister list detail sub-list\"]/div[3]/div/div/p/span[3]')\n",
    "try:\n",
    "    for v in time:\n",
    "        Run_time.append(v.text)\n",
    "except:\n",
    "    Run_time.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Ratings \n",
    "Rat=driver.find_elements(By.XPATH,'//*[@class=\"lister list detail sub-list\"]/div[3]/div/div/div[1]/div[1]')\n",
    "try:\n",
    "    for f in Rat:\n",
    "        Ratings.append(f.text)\n",
    "except:\n",
    "    Ratings.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Votes \n",
    "Vot=driver.find_elements(By.XPATH,'//*[@class=\"lister list detail sub-list\"]/div[3]/div/div/p[4]/span[2]')\n",
    "try:\n",
    "    for f in Vot:\n",
    "        Votes.append(f.text)\n",
    "except:\n",
    "    Votes.append('-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94157a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Name':Name,'Year_span':Year_span,'Genres':Genres,'Run_time':Run_time,'Ratings':Ratings,'Votes':Votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e64eb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>55 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,260,779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,319,257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,071,315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>313,316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>273,189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>643,819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>161,965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>114,793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>432,868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>138,613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                  Name    Year_span                    Genres  \\\n",
       "0     1.       Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1     2.       Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2     3.      The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3     4.        13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4     5.               The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..   ...                   ...          ...                       ...   \n",
       "95   96.        True Detective     (2014– )     Crime, Drama, Mystery   \n",
       "96   97.             Teen Wolf  (2011–2017)    Action, Drama, Fantasy   \n",
       "97   98.                The OA  (2016–2019)   Drama, Fantasy, Mystery   \n",
       "98   99.          The Simpsons     (1989– )         Animation, Comedy   \n",
       "99  100.  Desperate Housewives  (2004–2012)    Comedy, Drama, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    55 min     9.2  2,260,779  \n",
       "1    51 min     8.7  1,319,257  \n",
       "2    44 min     8.1  1,071,315  \n",
       "3    60 min     7.5    313,316  \n",
       "4    43 min     7.6    273,189  \n",
       "..      ...     ...        ...  \n",
       "95   55 min     8.9    643,819  \n",
       "96   41 min     7.7    161,965  \n",
       "97   60 min     7.8    114,793  \n",
       "98   22 min     8.7    432,868  \n",
       "99   45 min     7.6    138,613  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909333a",
   "metadata": {},
   "source": [
    "# Question-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070a065",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "\n",
    "Url = https://archive.ics.uci.edu/ You \n",
    "\n",
    "have to find the following details: \n",
    "A) Dataset name \n",
    "\n",
    "B) Data type \n",
    "\n",
    "C) Task \n",
    "\n",
    "D) Attribute type \n",
    "\n",
    "E) No of instances \n",
    "\n",
    "F) No of attribute G) Year \n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a21173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "# Load google maps\n",
    "driver.get(\" https://archive.ics.uci.edu/\")\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "View_Datasets = driver.find_element(By.XPATH,'//*[@class=\"flex flex-wrap justify-center gap-5\"]/a[1]')     \n",
    "View_Datasets.click()\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "Expand_all = driver.find_element(By.XPATH,'//*[@class=\"btn-primary btn-sm btn flex gap-2 rounded-full\"]/div[2]')     \n",
    "Expand_all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d30c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Lists\n",
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "Attribute_Type=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68aa6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Dataset_Name \n",
    "name=driver.find_elements(By.XPATH,'//*[@class=\"flex flex-col gap-1\"]/div/div/div[2]/h2/a')\n",
    "try:\n",
    "    for w in name:\n",
    "        Dataset_Name.append(w.text)\n",
    "except:\n",
    "    Dataset_Name.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Data_Type\n",
    "Data=driver.find_elements(By.XPATH,'//*[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[2]/span')\n",
    "try:\n",
    "    for a in Data:\n",
    "        Data_Type.append(a.text)\n",
    "except:\n",
    "    Data_Type.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Task \n",
    "Tas=driver.find_elements(By.XPATH,'//*[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[1]/span')\n",
    "try:\n",
    "    for d in Tas:\n",
    "        Task.append(d.text)\n",
    "except:\n",
    "    Task.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Attribute_Type \n",
    "Attr=driver.find_elements(By.XPATH,'//*[@class=\"flex flex-col gap-1\"]/div/div[2]/div/table/tbody/tr/td[2]')\n",
    "try:\n",
    "    for v in Attr:\n",
    "        Attribute_Type.append(v.text)\n",
    "except:\n",
    "    Attribute_Type.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the No_of_Instances \n",
    "Inst=driver.find_elements(By.XPATH,'//*[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[3]/span')\n",
    "try:\n",
    "    for f in Inst:\n",
    "        No_of_Instances.append(f.text.replace('Instances',''))\n",
    "except:\n",
    "    No_of_Instances.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the No_of_Attribute \n",
    "Attrib=driver.find_elements(By.XPATH,'//*[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[4]/span')\n",
    "try:\n",
    "    for f in Attrib:\n",
    "        No_of_Attribute.append(f.text.replace('Features',''))\n",
    "except:\n",
    "    No_of_Attribute.append('-')\n",
    "    \n",
    "    \n",
    "#scraping the Year \n",
    "Yer=driver.find_elements(By.XPATH,'//*[@class=\"flex flex-col gap-1\"]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "try:\n",
    "    for f in Yer:\n",
    "        Year.append(f.text)\n",
    "except:\n",
    "    Year.append('-')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3395a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Dataset_Name':Dataset_Name,'Data_Type':Data_Type,'Task':Task,'Attribute_Type':Attribute_Type,'No_of_Instances':No_of_Instances,'No_of_Attribute':No_of_Attribute,'Year':Year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a9ef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K</td>\n",
       "      <td>16</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K</td>\n",
       "      <td>7</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K</td>\n",
       "      <td>14</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900</td>\n",
       "      <td>8</td>\n",
       "      <td>8/14/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K</td>\n",
       "      <td>12</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K</td>\n",
       "      <td>6</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>45.21K</td>\n",
       "      <td>17</td>\n",
       "      <td>2/14/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8.12K</td>\n",
       "      <td>22</td>\n",
       "      <td>4/27/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4.18K</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Student Performance</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>649</td>\n",
       "      <td>33</td>\n",
       "      <td>11/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K</td>\n",
       "      <td>14</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Online Retail</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>541.91K</td>\n",
       "      <td>8</td>\n",
       "      <td>11/6/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>205</td>\n",
       "      <td>25</td>\n",
       "      <td>5/19/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Statlog (German Credit Data)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1K</td>\n",
       "      <td>20</td>\n",
       "      <td>11/17/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>286</td>\n",
       "      <td>9</td>\n",
       "      <td>7/11/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>398</td>\n",
       "      <td>7</td>\n",
       "      <td>7/7/1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>699</td>\n",
       "      <td>9</td>\n",
       "      <td>7/15/1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>4.6K</td>\n",
       "      <td>57</td>\n",
       "      <td>7/1/1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Predict Students' Dropout and Academic Success</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>4.42K</td>\n",
       "      <td>36</td>\n",
       "      <td>12/13/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Glass Identification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>214</td>\n",
       "      <td>9</td>\n",
       "      <td>9/1/1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Dataset_Name  \\\n",
       "0                                             Iris   \n",
       "1                                 Dry Bean Dataset   \n",
       "2                                    Heart Disease   \n",
       "3                       Rice (Cammeo and Osmancik)   \n",
       "4                                            Adult   \n",
       "5                                           Raisin   \n",
       "6             Breast Cancer Wisconsin (Diagnostic)   \n",
       "7                                             Wine   \n",
       "8                                     Wine Quality   \n",
       "9                                         Diabetes   \n",
       "10                                  Car Evaluation   \n",
       "11                                  Bank Marketing   \n",
       "12                                        Mushroom   \n",
       "13                                         Abalone   \n",
       "14                             Student Performance   \n",
       "15                                   Census Income   \n",
       "16                                   Online Retail   \n",
       "17                                      Automobile   \n",
       "18                    Statlog (German Credit Data)   \n",
       "19                                   Breast Cancer   \n",
       "20                                        Auto MPG   \n",
       "21              Breast Cancer Wisconsin (Original)   \n",
       "22                                        Spambase   \n",
       "23  Predict Students' Dropout and Academic Success   \n",
       "24                            Glass Identification   \n",
       "\n",
       "                                Data_Type                        Task  \\\n",
       "0                                 Tabular              Classification   \n",
       "1                            Multivariate              Classification   \n",
       "2                            Multivariate              Classification   \n",
       "3                            Multivariate              Classification   \n",
       "4                            Multivariate              Classification   \n",
       "5                            Multivariate              Classification   \n",
       "6                            Multivariate              Classification   \n",
       "7                                 Tabular              Classification   \n",
       "8                            Multivariate  Classification, Regression   \n",
       "9               Multivariate, Time-Series              Classification   \n",
       "10                           Multivariate              Classification   \n",
       "11                           Multivariate              Classification   \n",
       "12                           Multivariate              Classification   \n",
       "13                                Tabular  Classification, Regression   \n",
       "14                           Multivariate  Classification, Regression   \n",
       "15                           Multivariate              Classification   \n",
       "16  Multivariate, Sequential, Time-Series  Classification, Clustering   \n",
       "17                           Multivariate                  Regression   \n",
       "18                           Multivariate              Classification   \n",
       "19                           Multivariate              Classification   \n",
       "20                           Multivariate                  Regression   \n",
       "21                           Multivariate              Classification   \n",
       "22                           Multivariate              Classification   \n",
       "23                                Tabular              Classification   \n",
       "24                           Multivariate              Classification   \n",
       "\n",
       "                Attribute_Type No_of_Instances No_of_Attribute        Year  \n",
       "0                         Real            150               4     7/1/1988  \n",
       "1                Integer, Real         13.61K              16    9/14/2020  \n",
       "2   Categorical, Integer, Real            303              13     7/1/1988  \n",
       "3                         Real          3.81K               7    10/6/2019  \n",
       "4         Categorical, Integer         48.84K              14     5/1/1996  \n",
       "5                Real, Integer            900               8    8/14/2023  \n",
       "6                         Real            569              30    11/1/1995  \n",
       "7                Integer, Real            178              13     7/1/1991  \n",
       "8                         Real           4.9K              12    10/7/2009  \n",
       "9         Categorical, Integer              1              20          N/A  \n",
       "10                 Categorical          1.73K               6     6/1/1997  \n",
       "11        Categorical, Integer         45.21K              17    2/14/2012  \n",
       "12                 Categorical          8.12K              22    4/27/1987  \n",
       "13  Categorical, Integer, Real          4.18K               8    12/1/1995  \n",
       "14                     Integer            649              33   11/27/2014  \n",
       "15        Categorical, Integer         48.84K              14     5/1/1996  \n",
       "16               Integer, Real        541.91K               8    11/6/2015  \n",
       "17  Categorical, Integer, Real            205              25    5/19/1987  \n",
       "18        Categorical, Integer             1K              20   11/17/1994  \n",
       "19                 Categorical            286               9    7/11/1988  \n",
       "20  Real, Categorical, Integer            398               7     7/7/1993  \n",
       "21                     Integer            699               9    7/15/1992  \n",
       "22               Integer, Real           4.6K              57     7/1/1999  \n",
       "23  Real, Categorical, Integer          4.42K              36   12/13/2021  \n",
       "24                        Real            214               9     9/1/1987  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208551e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
