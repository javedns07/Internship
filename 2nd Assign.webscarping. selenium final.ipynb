{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f415dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241b81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the path of chrome webdriver\n",
    "path=\"C://chromedriver.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef1c20",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "    \n",
    "1.First get the webpage **https://www.shine.com/**\n",
    "\n",
    "2.Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "3.Then click the searchbutton.\n",
    "\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5.Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e52d572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome browser to webdriver \n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c5caed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.First get the webpage\n",
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b10f209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f1c251ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "#finding and clicking the job title input box\n",
    "\n",
    "job_=driver.find_element(By.XPATH,\"/html/body/div/header/div[3]/div/div/div[1]/div/input\")\n",
    "job_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "58a1db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Data Analyst\n",
    "\n",
    "title=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "title.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ddcf215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input location Bangalore \n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[3]/div/input[1]\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc722e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for blocking the pop up\n",
    "\n",
    "pop_up=driver.find_element(By.XPATH,\"/html/body/div/div[2]/div/div/button\")\n",
    "pop_up.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8618f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.click to the search bar.\n",
    "search_button=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "93b85596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists \n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience=[]\n",
    "count=10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0332308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Then scrape the data for the first 10 jobs results you get.\n",
    "count=10\n",
    "\n",
    "# job titles \n",
    "\n",
    "for tit in driver.find_elements(By.XPATH,\"//h2[@itemprop='name']\"):\n",
    "    if len(job_title)<count:\n",
    "        job_title.append(tit.text)\n",
    "        \n",
    "# job locations \n",
    "\n",
    "for loc in driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2']\"):\n",
    "    if len(job_location)<count:\n",
    "        job_location.append(loc.text.replace('\\n','')) \n",
    "        \n",
    "#company name \n",
    "\n",
    "for com in driver.find_elements(By.XPATH,\"//div[@class='jobCard_jobCard_cName__mYnow']\"):\n",
    "    if len(company_name)<count:\n",
    "        company_name.append(com.text.capitalize())\n",
    "        \n",
    "# experience\n",
    "\n",
    "for exp in driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t']\"):\n",
    "    if len(experience)<count:\n",
    "        experience.append(exp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2aff61bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Unnati</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst , Senior Data Analyst , Data Anal...</td>\n",
       "      <td>Other Maharashtra</td>\n",
       "      <td>Aryantech india pvt ltd</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring candidates for Marketing with Fare &amp; Da...</td>\n",
       "      <td>Noida+2</td>\n",
       "      <td>Sharda it services</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Other Maharashtra+1</td>\n",
       "      <td>Clairvoyant</td>\n",
       "      <td>6 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring for Fare &amp; Data Analyst-Travel process</td>\n",
       "      <td>Noida+2</td>\n",
       "      <td>Sharda it services</td>\n",
       "      <td>1 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>All India</td>\n",
       "      <td>Titan company limited</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Risk and Finance Big Data Analyst</td>\n",
       "      <td>Other Karnataka</td>\n",
       "      <td>Cygnus professionals inc.</td>\n",
       "      <td>3 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst | Sql , Python , GCP , Cassandra ...</td>\n",
       "      <td>Other Karnataka</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>7 to 11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Supply Chain Data Analyst</td>\n",
       "      <td>Other Maharashtra+1</td>\n",
       "      <td>Emerson career site</td>\n",
       "      <td>3 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Other Karnataka</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title         Job Location  \\\n",
       "0                                       Data Analyst                Delhi   \n",
       "1  Data Analyst , Senior Data Analyst , Data Anal...    Other Maharashtra   \n",
       "2  Hiring candidates for Marketing with Fare & Da...              Noida+2   \n",
       "3                                Senior Data Analyst  Other Maharashtra+1   \n",
       "4      Hiring for Fare & Data Analyst-Travel process              Noida+2   \n",
       "5                                       Data Analyst            All India   \n",
       "6                  Risk and Finance Big Data Analyst      Other Karnataka   \n",
       "7  Data Analyst | Sql , Python , GCP , Cassandra ...      Other Karnataka   \n",
       "8                          Supply Chain Data Analyst  Other Maharashtra+1   \n",
       "9                                       Data Analyst      Other Karnataka   \n",
       "\n",
       "                Company Name Experience Required  \n",
       "0                     Unnati          3 to 5 Yrs  \n",
       "1    Aryantech india pvt ltd          0 to 3 Yrs  \n",
       "2         Sharda it services          2 to 5 Yrs  \n",
       "3                Clairvoyant          6 to 9 Yrs  \n",
       "4         Sharda it services          1 to 6 Yrs  \n",
       "5      Titan company limited         5 to 10 Yrs  \n",
       "6  Cygnus professionals inc.          3 to 7 Yrs  \n",
       "7                      Cisco         7 to 11 Yrs  \n",
       "8        Emerson career site          3 to 7 Yrs  \n",
       "9                     Airbus          2 to 6 Yrs  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.created a dataframe of the scraped data.\n",
    "\n",
    "df=pd.DataFrame({'Job Title':job_title, 'Job Location':job_location,'Company Name':company_name,'Experience Required':experience })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763acc6a",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.shine.com/\n",
    "\n",
    "2.Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "\n",
    "3.Then click the search button.\n",
    "\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5.Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4cc5f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca17236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.First get the webpage\n",
    "\n",
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4c283e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b76ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "#finding and clicking the job title input box\n",
    "\n",
    "job=driver.find_element(By.XPATH,\"/html/body/div/header/div[3]/div/div/div[1]/div/input\")\n",
    "job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30c5849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering Data Scientist as input to the inbox\n",
    "\n",
    "new=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "new.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8277875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering Bangalore by locating element by XPATH\n",
    "\n",
    "loc=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[3]/div/input[1]\")\n",
    "loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "28cbb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for blocking the pop-up\n",
    "\n",
    "pop_up=driver.find_element(By.XPATH,\"/html/body/div/div[2]/div/div/button\")\n",
    "pop_up.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "314893db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.click the search button.\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03dd05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making empty lists to store specific information\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3ca0280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.scraping the data for the first 10 jobs results we got.\n",
    "count=10\n",
    "\n",
    "# job titles\n",
    "\n",
    "for p in driver.find_elements(By.XPATH,\"//h2[@itemprop='name']\"):\n",
    "    if len(job_title)<count:\n",
    "        job_title.append(p.text)\n",
    "\n",
    "# job location\n",
    "\n",
    "for l in driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2']\"):\n",
    "    if len(job_location)<count:\n",
    "        job_location.append(l.text.replace('\\n',''))   \n",
    "        \n",
    "# company name \n",
    "\n",
    "for c in driver.find_elements(By.XPATH,\"//div[@class='jobCard_jobCard_cName__mYnow']\"):\n",
    "    if len(company_name)<count:\n",
    "        company_name.append(c.text.capitalize())\n",
    "        \n",
    "# experience  \n",
    "\n",
    "for e in driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t']\"):\n",
    "    if len(experience)<count:\n",
    "        experience.append(e.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5341ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Australia+2</td>\n",
       "      <td>Advance immigrations</td>\n",
       "      <td>8 to 13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Virgin Islands (UK)+3</td>\n",
       "      <td>Skywalk visa immigration services l...</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML Data Scientist</td>\n",
       "      <td>Bangalore+3</td>\n",
       "      <td>Gujarat facility services hiring fo...</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist | Senior Data Scientist Chennai</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Talent leads hr solutions pvt ltd</td>\n",
       "      <td>8 to 13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Canada+15</td>\n",
       "      <td>Renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Canada+15</td>\n",
       "      <td>Renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Canada+15</td>\n",
       "      <td>Renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram+1</td>\n",
       "      <td>Right advisors private limited</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/Data Analyst-17740</td>\n",
       "      <td>All India</td>\n",
       "      <td>Gemraj technologies ltd</td>\n",
       "      <td>3 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - Claims Analysis</td>\n",
       "      <td>Other Karnataka</td>\n",
       "      <td>Molecular connections</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job Title           Job Location  \\\n",
       "0                                  Data Scientist            Australia+2   \n",
       "1                                  Data Scientist  Virgin Islands (UK)+3   \n",
       "2                               ML Data Scientist            Bangalore+3   \n",
       "3  Data Scientist | Senior Data Scientist Chennai                Chennai   \n",
       "4                   Data Scientist Urgent Vacancy              Canada+15   \n",
       "5                   Data Scientist Urgent Vacancy              Canada+15   \n",
       "6                   Data Scientist Urgent Vacancy              Canada+15   \n",
       "7                                  Data Scientist             Gurugram+1   \n",
       "8               Data Scientist/Data Analyst-17740              All India   \n",
       "9         Senior Data Scientist - Claims Analysis        Other Karnataka   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                    Advance immigrations         8 to 13 Yrs  \n",
       "1  Skywalk visa immigration services l...          2 to 7 Yrs  \n",
       "2  Gujarat facility services hiring fo...          5 to 8 Yrs  \n",
       "3       Talent leads hr solutions pvt ltd         8 to 13 Yrs  \n",
       "4                      Renuka interprises          0 to 4 Yrs  \n",
       "5                      Renuka interprises          0 to 4 Yrs  \n",
       "6                      Renuka interprises          0 to 4 Yrs  \n",
       "7          Right advisors private limited          2 to 7 Yrs  \n",
       "8                 Gemraj technologies ltd          3 to 7 Yrs  \n",
       "9                   Molecular connections          2 to 5 Yrs  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.created a dataframe of the scraped data.\n",
    "\n",
    "df_1=pd.DataFrame({'Job Title':job_title, 'Job Location':job_location,'Company Name':company_name,'Experience Required':experience })\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce77b8a",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "    \n",
    "1.first get the web page https://www.shine.com/\n",
    "    \n",
    "2.Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "\n",
    "3.Then click the search button.\n",
    "\n",
    "4.Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "5.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "6.Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "78f0edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome browser to webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac1d14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.first getting the web page https://www.shine.com/\n",
    "\n",
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ffd488a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95ea29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "#finding and clicking the job title input box\n",
    "\n",
    "input_click=driver.find_element(By.XPATH,\"/html/body/div/header/div[3]/div/div/div[1]/div/input\")\n",
    "input_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7c322249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Data Scientist \n",
    "\n",
    "position=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "position.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a92cd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search button and clicking\n",
    "\n",
    "search_=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2255bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.click to the search button.\n",
    "\n",
    "loc_click=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div/ul/li[1]/button\")\n",
    "loc_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6e0ca72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Then apply the location filter and salary filter by checking the respective boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a1595acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter input as Delhi\n",
    "\n",
    "loc=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/div/div[3]/div/div/div/ul/li[1]/input')\n",
    "loc.send_keys('Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8a7191a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tick to the delhi check box\n",
    "\n",
    "box=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/div/div[3]/div/div/div/ul/li[2]/span/label\")\n",
    "box.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b0b58df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to the show results button\n",
    "\n",
    "result=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/div/div[4]/button[2]\")\n",
    "result.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1cb86a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding and clicking on the salary filter button\n",
    "\n",
    "sal_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div/div/div[2]/div/ul/li[3]/button\")\n",
    "sal_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f373b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tick to the 3-5L check box\n",
    "\n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div[3]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a5546798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click tothe show results button\n",
    "\n",
    "show_result=driver.find_element(By.XPATH,\"/html/body/div[3]/div/div/div/div[4]/button[2]\")\n",
    "show_result.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e81f9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "616f27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.scraping the data for the first 10 jobs results we got.\n",
    "# count set as 10 to scrap the first 10(0-9) results\n",
    "count=10  \n",
    "\n",
    "# job titles\n",
    "\n",
    "for p in driver.find_elements(By.XPATH,\"//h2[@itemprop='name']\"):\n",
    "    if len(job_title)<count:\n",
    "        job_title.append(p.text)\n",
    "        \n",
    "# job locations\n",
    "\n",
    "for l in driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2']\"):\n",
    "    if len(job_location)<count:\n",
    "        job_location.append(l.text.replace('\\n',''))   \n",
    "        \n",
    "# company names\n",
    "\n",
    "for c in driver.find_elements(By.XPATH,\"//div[@class='jobCard_jobCard_cName__mYnow']\"):\n",
    "    if len(company_name)<count:\n",
    "        company_name.append(c.text.capitalize())\n",
    "        \n",
    "# experience \n",
    "\n",
    "for e in driver.find_elements(By.XPATH,\"//div[@class=' jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t']\"):\n",
    "    if len(experience)<count:\n",
    "        experience.append(e.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "05bc7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi+4</td>\n",
       "      <td>Acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring candidates for Marketing with Fare &amp; Da...</td>\n",
       "      <td>Delhi+2</td>\n",
       "      <td>Sharda it services</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring for Fare &amp; Data Analyst-Travel process</td>\n",
       "      <td>Delhi+2</td>\n",
       "      <td>Sharda it services</td>\n",
       "      <td>1 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Delhi+6</td>\n",
       "      <td>Techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Sas Programmer</td>\n",
       "      <td>Delhi+8</td>\n",
       "      <td>Techno endura</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical SAS</td>\n",
       "      <td>Delhi+8</td>\n",
       "      <td>Techno endura</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apprentice Trainee</td>\n",
       "      <td>Delhi+9</td>\n",
       "      <td>Mahima consultancy</td>\n",
       "      <td>0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clinical Data Management</td>\n",
       "      <td>Delhi+6</td>\n",
       "      <td>Techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bioanalytical Research</td>\n",
       "      <td>Delhi+6</td>\n",
       "      <td>Techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Clinical Data Management</td>\n",
       "      <td>Delhi+6</td>\n",
       "      <td>Techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title Job Location  \\\n",
       "0                                     Data Scientist      Delhi+4   \n",
       "1  Hiring candidates for Marketing with Fare & Da...      Delhi+2   \n",
       "2      Hiring for Fare & Data Analyst-Travel process      Delhi+2   \n",
       "3                              Clinical Data Analyst      Delhi+6   \n",
       "4                            Clinical Sas Programmer      Delhi+8   \n",
       "5                                       Clinical SAS      Delhi+8   \n",
       "6                                 Apprentice Trainee      Delhi+9   \n",
       "7                           Clinical Data Management      Delhi+6   \n",
       "8                             Bioanalytical Research      Delhi+6   \n",
       "9                    Junior Clinical Data Management      Delhi+6   \n",
       "\n",
       "                    Company Name Experience Required  \n",
       "0  Acme services private limited          3 to 5 Yrs  \n",
       "1             Sharda it services          2 to 5 Yrs  \n",
       "2             Sharda it services          1 to 6 Yrs  \n",
       "3                  Techno endura           0 to 1 Yr  \n",
       "4                  Techno endura          0 to 2 Yrs  \n",
       "5                  Techno endura          0 to 2 Yrs  \n",
       "6             Mahima consultancy               0 Yrs  \n",
       "7                  Techno endura           0 to 1 Yr  \n",
       "8                  Techno endura           0 to 1 Yr  \n",
       "9                  Techno endura           0 to 1 Yr  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.created a dataframe of the scraped data.\n",
    "df_1=pd.DataFrame({'Job Title':job_title, 'Job Location':job_location,'Company Name':company_name,'Experience Required':experience })\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef7c70",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904e798",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "1.Brand\n",
    "\n",
    "2.Product Description\n",
    "\n",
    "3.Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "\n",
    "1.Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "        \n",
    "2.Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "\n",
    "3.After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "\n",
    "4.\tAfter scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "\n",
    "5.\tNow scrape data from this page as usual\n",
    "\n",
    "6.\tRepeat this until you get data for 100sunglasses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e575545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome browser to webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bef1afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "42ceb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7d64ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4520be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding and clicking the search input box\n",
    "\n",
    "first_click=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "first_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ff07d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending input Sunglasses in the search box\n",
    "\n",
    "item=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "item.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "79e765e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to the search button\n",
    "\n",
    "second_click=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button\")\n",
    "second_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a189ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists \n",
    "brand_name=[]\n",
    "price_name=[]\n",
    "descs_name=[]\n",
    "offs_name=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b8babd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data till 100 count\n",
    "count=100\n",
    "\n",
    "#for page 1\n",
    "for i in range(1,2):\n",
    "    \n",
    "    # brand name\n",
    "    \n",
    "    for brd in driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\"):\n",
    "        if len(brand_name)<count:\n",
    "            brand_name.append(brd.text) \n",
    "        \n",
    "    # prices \n",
    "    \n",
    "    for prc in driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\"):\n",
    "        if len(price_name)<count:\n",
    "            price_name.append(prc.text)\n",
    "        \n",
    "    #description\n",
    "    \n",
    "    for dsc in driver.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "        if len(descs_name)<count: \n",
    "            descs_name.append(dsc.text)\n",
    "        \n",
    "    # offers  \n",
    "    \n",
    "    for ofr in driver.find_elements(By.CLASS_NAME,'_3Ay6Sb'):\n",
    "        if len(offs_name)<count: \n",
    "            offs_name.append(ofr.text)   \n",
    "\n",
    "        \n",
    "    #next page button for page 1 \n",
    "    \n",
    "    next_button=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span\")\n",
    "    next_button.click()\n",
    "    \n",
    "    #sleep for 3 secs\n",
    "    sleep(3)\n",
    "\n",
    "\n",
    "#for page 2 and beyond    \n",
    "for i in range(2,4):\n",
    "    \n",
    "    \n",
    "    # brand name \n",
    "    \n",
    "    for brd in driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\"):\n",
    "        if len(brand_name)<count:\n",
    "            brand_name.append(brd.text)\n",
    "            \n",
    "    # prices  \n",
    "    \n",
    "    for prc in driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\"):\n",
    "        if len(price_name)<count:\n",
    "            price_name.append(prc.text)\n",
    "    \n",
    "    # description\n",
    "    \n",
    "    for dsc in driver.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "        if len(descs_name)<count: \n",
    "            descs_name.append(dsc.text)\n",
    "            \n",
    "    # offers \n",
    "    \n",
    "    for ofr in driver.find_elements(By.CLASS_NAME,'_3Ay6Sb'):\n",
    "        if len(offs_name)<count: \n",
    "            offs_name.append(ofr.text)\n",
    "            \n",
    "    #next page button for page 2 and beyond (scrapping till we get 100 results)\n",
    "    \n",
    "    next__=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span\")\n",
    "    next__.click()  \n",
    "    \n",
    "    #sleep for 2 secs\n",
    "    sleep(2)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3e75eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eyenaks</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹346</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>Polarized, UV Protection Wayfarer Sunglasses (51)</td>\n",
       "      <td>₹1,236</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Wayfarer, Sports, Spectacle , Re...</td>\n",
       "      <td>₹129</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹169</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹169</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Retro Square Sunglasse...</td>\n",
       "      <td>₹539</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Round, Wayfarer Sunglasses (52)</td>\n",
       "      <td>₹745</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Rectangular Sunglasses (56)</td>\n",
       "      <td>₹854</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹590</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹385</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                  Price Description   Price  \\\n",
       "0          Eyenaks   UV Protection Rectangular Sunglasses (Free Size)    ₹346   \n",
       "1      Eyewearlabs  Polarized, UV Protection Wayfarer Sunglasses (51)  ₹1,236   \n",
       "2          ROADWAY  UV Protection Wayfarer, Sports, Spectacle , Re...    ₹129   \n",
       "3             SRPM             UV Protection Wayfarer Sunglasses (50)    ₹169   \n",
       "4          ROADWAY  UV Protection Retro Square Sunglasses (Free Size)    ₹169   \n",
       "..             ...                                                ...     ...   \n",
       "95        Fastrack  Gradient, UV Protection Retro Square Sunglasse...    ₹539   \n",
       "96          AISLIN      UV Protection Round, Wayfarer Sunglasses (52)    ₹745   \n",
       "97       ROYAL SON              Polarized Rectangular Sunglasses (56)    ₹854   \n",
       "98    Singco India  Gradient, Toughened Glass Lens, UV Protection ...    ₹590   \n",
       "99  ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹385   \n",
       "\n",
       "   Discount  \n",
       "0   76% off  \n",
       "1   65% off  \n",
       "2   90% off  \n",
       "3   86% off  \n",
       "4   86% off  \n",
       "..      ...  \n",
       "95  72% off  \n",
       "96  71% off  \n",
       "97  63% off  \n",
       "98  20% off  \n",
       "99  82% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#created a dataframe of the scraped data.\n",
    "\n",
    "df_2=pd.DataFrame({'Brand Name':brand_name,'Price Description':descs_name,'Price':price_name,'Discount':offs_name})\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2421598",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05370a29",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product- reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "\n",
    "1.\tRating\n",
    "\n",
    "2.\tReview summary\n",
    "\n",
    "3.\tFull review\n",
    "\n",
    "4.\tYou have to scrape this data for first 100reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "625aef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting chrome browser to webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "48b19b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open flipkart \n",
    "\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cc509ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b9f3e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists \n",
    "ratings=[]\n",
    "review=[]\n",
    "full_review=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5e9e0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaping data till we get 100 results\n",
    "count=100\n",
    "\n",
    "#for page 1\n",
    "for i in range(1,2):\n",
    "    \n",
    "    # ratings \n",
    "    \n",
    "    for rtg in driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        if len(ratings)<count:\n",
    "            ratings.append(rtg.text) \n",
    "        \n",
    "     # reviews  \n",
    "    \n",
    "    for rws in driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\"):\n",
    "         if len(review)<count:\n",
    "            review.append(rws.text)\n",
    "        \n",
    "    # full reviews\n",
    "    \n",
    "    for frws in driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\"):\n",
    "         if len(full_review)<count:\n",
    "            full_review.append(frws.text.replace('\\n',' '))\n",
    "        \n",
    "\n",
    "     #next page button for page1 \n",
    "    \n",
    "    next_=driver.find_element(By.XPATH,\"(//a[@class='_1LKTO3'])[1]\")\n",
    "    next_.click()\n",
    "    \n",
    "    #sleep\n",
    "    sleep(3)\n",
    "    \n",
    "    \n",
    "#for page 2 and next page  \n",
    "\n",
    "for i in range(2,11):\n",
    "    \n",
    "    # ratings\n",
    "    \n",
    "    for rtg in driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        if len(ratings)<count:\n",
    "            ratings.append(rtg.text) \n",
    "        \n",
    "     # reviews \n",
    "    \n",
    "    for rws in driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\"):\n",
    "         if len(review)<count:\n",
    "            review.append(rws.text)\n",
    "        \n",
    "    # full reviews\n",
    "    \n",
    "    for frws in driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\"):\n",
    "         if len(full_review)<count:\n",
    "            full_review.append(frws.text.replace('\\n',' '))\n",
    "        \n",
    "    #next page button for page 2 and next page\n",
    "    \n",
    "    next__=driver.find_element(By.XPATH,\"(//a[@class='_1LKTO3'])[2]\")\n",
    "    next__.click()\n",
    "    \n",
    "    #sleep\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0916e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>V Good all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome Best battery backup A perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanks Flipkart For this amazing deal! I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Excellent Fabulous Adorable Iphone 11 Value fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I switched to IOS for long term use and for be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Perfect iPhone on this budget!! Camera and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings       Review Summary  \\\n",
       "0        5     Perfect product!   \n",
       "1        5            Wonderful   \n",
       "2        5             Terrific   \n",
       "3        5       Classy product   \n",
       "4        5  Best in the market!   \n",
       "..     ...                  ...   \n",
       "95       5   Highly recommended   \n",
       "96       5            Wonderful   \n",
       "97       4            Very Good   \n",
       "98       5            Brilliant   \n",
       "99       5       Classy product   \n",
       "\n",
       "                                          Full Review  \n",
       "0                                          V Good all  \n",
       "1                              This is amazing at all  \n",
       "2                                      Very very good  \n",
       "3   Camera is awesome Best battery backup A perfor...  \n",
       "4                                         Good Camera  \n",
       "..                                                ...  \n",
       "95  Thanks Flipkart For this amazing deal! I had a...  \n",
       "96  Excellent Fabulous Adorable Iphone 11 Value fo...  \n",
       "97  I switched to IOS for long term use and for be...  \n",
       "98  Perfect iPhone on this budget!! Camera and the...  \n",
       "99                 Outstanding performance this phone  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing the data\n",
    "\n",
    "df_3=pd.DataFrame({'Ratings':ratings,'Review Summary':review,'Full Review':full_review})\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a667e",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325e8e3",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "\n",
    "1.\tBrand\n",
    "\n",
    "2.\tProduct Description\n",
    "\n",
    "3.\tPrice\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bb9a2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting chrome browser to webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5a66082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open flipkart \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "98feef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1cd77a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to the search input box\n",
    "\n",
    "first_click=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "first_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dac199b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending input Sneakers in the search box\n",
    "\n",
    "item=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "item.send_keys(\"Sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "79fbee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click to the search button\n",
    "\n",
    "second_click=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button\")\n",
    "second_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d77c44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making empty lists to store specific information\n",
    "brand=[]\n",
    "price=[]\n",
    "desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "26e4c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count till we get 100 results\n",
    "count=100\n",
    "\n",
    "#for page 1\n",
    "for i in range(1,2):\n",
    "    \n",
    "     # brand name \n",
    "    for brd in driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\"):\n",
    "        brand.append(brd.text) \n",
    "        \n",
    "     # prices      \n",
    "    for prc in driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\"):\n",
    "        price.append(prc.text)\n",
    "        \n",
    "     # description     \n",
    "    for dcp in driver.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "        desc.append(dcp.text)\n",
    "        \n",
    "        \n",
    "    #next page button for page 1\n",
    "    next_=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span\")\n",
    "    next_.click()\n",
    "    sleep(3)\n",
    "    \n",
    "\n",
    "#for page 2 and next page \n",
    "\n",
    "for i in range(2,4):\n",
    "    \n",
    "    \n",
    "    # brand name \n",
    "        \n",
    "    for brd in driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\"):\n",
    "        if len(brand)<count:\n",
    "            brand.append(brd.text)\n",
    "            \n",
    "            \n",
    "     # prices \n",
    "    \n",
    "    for prc in driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\"):\n",
    "        if len(price)<count:\n",
    "            price.append(prc.text)\n",
    "            \n",
    "    \n",
    "     # description  \n",
    "        \n",
    "    for dcp in driver.find_elements(By.CLASS_NAME,'IRpwTa'):\n",
    "        if len(desc)<count: \n",
    "            desc.append(dcp.text)\n",
    "            \n",
    "    \n",
    "    #next page button for page 2 and next page\n",
    "    \n",
    "    next__=driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span\")\n",
    "    next__.click()    \n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c3f09167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>₹339</td>\n",
       "      <td>Fashionable Canvas Casual Partywear Outdoor Sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>₹419</td>\n",
       "      <td>kardam&amp;sons luxury fashionable Stylish Light W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>₹299</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>₹299</td>\n",
       "      <td>Trending Stylish Casual Outdoor Shoes Sneakers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>₹1,737</td>\n",
       "      <td>Casual Sneaker Shoes for Men | Soft Cushioned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Abros</td>\n",
       "      <td>₹682</td>\n",
       "      <td>ORBIT Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>₹1,456</td>\n",
       "      <td>OG-01 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>₹1,055</td>\n",
       "      <td>VIBGYOR Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>₹989</td>\n",
       "      <td>SM-671 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RUN SEVEN</td>\n",
       "      <td>₹999</td>\n",
       "      <td>( by GO21 ) Soft Insole, Slip-Resistance|Walki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand   Price                                        Description\n",
       "0   kardam&sons    ₹339  Fashionable Canvas Casual Partywear Outdoor Sn...\n",
       "1   kardam&sons    ₹419  kardam&sons luxury fashionable Stylish Light W...\n",
       "2     Deals4you    ₹299                                 Sneakers For Women\n",
       "3      URBANBOX    ₹299  Trending Stylish Casual Outdoor Shoes Sneakers...\n",
       "4      RED TAPE  ₹1,737  Casual Sneaker Shoes for Men | Soft Cushioned ...\n",
       "..          ...     ...                                                ...\n",
       "95        Abros    ₹682                             ORBIT Sneakers For Men\n",
       "96       CAMPUS  ₹1,456                             OG-01 Sneakers For Men\n",
       "97       CAMPUS  ₹1,055                           VIBGYOR Sneakers For Men\n",
       "98        Sparx    ₹989                            SM-671 Sneakers For Men\n",
       "99    RUN SEVEN    ₹999  ( by GO21 ) Soft Insole, Slip-Resistance|Walki...\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe and storing the data\n",
    "\n",
    "df_4=pd.DataFrame({'Brand':brand,'Price':price,'Description':desc})\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "af631869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************\n",
      "                                                SELENIUM                                                                \n",
      "******************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*'*126)\n",
    "print('                                                SELENIUM                                                                ')\n",
    "print('*'*126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbddeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
